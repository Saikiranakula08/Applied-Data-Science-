{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saikiranakula08/Applied-Data-Science-/blob/main/Kaggle_challange_group8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyxcnYZj676q",
        "outputId": "7f39d252-1f25-42c7-ec57-ab895549ac4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming you have a DataFrame called df and a target column called 'target'\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the dataset first\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Identify categorical columns\n",
        "cat_cols = X_train.select_dtypes(include='object').columns\n",
        "\n",
        "# Apply label encoding\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
        "    X_val[col] = le.transform(X_val[col].astype(str))\n",
        "\n"
      ],
      "metadata": {
        "id": "idTyKKMd7SG5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example: binary classification\n",
        "X = train_df.drop(columns=['Transported', 'PassengerId', 'Name', 'Cabin'])\n",
        "y = train_df['Transported'].astype(int)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train XGBoost\n",
        "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# SHAP explainer\n",
        "explainer = shap.Explainer(model, X_train)\n",
        "shap_values = explainer(X_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "UBNETL6B6922",
        "outputId": "6e7b5435-3359-4f23-ad67-624cb4453cfa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['Transported', 'PassengerId', 'Name', 'Cabin'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-2094969058.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Example: binary classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Transported'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PassengerId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cabin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Transported'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Transported', 'PassengerId', 'Name', 'Cabin'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, X_val)\n"
      ],
      "metadata": {
        "id": "Vxct9WxK7IEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tCUEbqyd7D2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_datapath ='https://raw.githubusercontent.com/Kaggle-challange-group8/Titanic_space_ship_group_8/refs/heads/main/test-3.csv'\n",
        "test_df = pd.read_csv(test_datapath)\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "xMKhNaMKb4CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset='https://raw.githubusercontent.com/Kaggle-challange-group8/Titanic_space_ship_group_8/refs/heads/main/train-3.csv'\n",
        "train_df=pd.read_csv(train_dataset)\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "pNr9CebodRNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "id": "oNOkfF8p4ruo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.columns"
      ],
      "metadata": {
        "id": "pGh-Y8sb45Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shapes\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)\n",
        "\n",
        "# Check nulls\n",
        "train_df.isnull().sum().sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "MRhFfCS-5MXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, MaxPooling1D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "-wmLf6O25VGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set random seed\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "JIE_LXNoUpbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle-challange-group8/Titanic_space_ship_group_8/refs/heads/main/train-3.csv\")\n",
        "test_df = pd.read_csv(\"https://raw.githubusercontent.com/Kaggle-challange-group8/Titanic_space_ship_group_8/refs/heads/main/test-3.csv\")\n"
      ],
      "metadata": {
        "id": "44rYFSK6UtVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_passenger_ids = test_df['PassengerId']\n"
      ],
      "metadata": {
        "id": "X_NqPQupUt80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class Distribution\n",
        "sns.countplot(x='Transported', data=train_df)\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hmmkYMQbUxPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.heatmap(train_df.isnull(), cbar=False, yticklabels=False, cmap=\"viridis\")\n",
        "plt.title(\"Missing Values\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mA1q7A2UUxHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap\n",
        "df_corr = train_df.copy()\n",
        "df_corr['Transported'] = df_corr['Transported'].astype(int)\n",
        "df_corr = df_corr.select_dtypes(include=[np.number])\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df_corr.corr(), annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NCJxeNImU6bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Age vs RoomService (colored by Transported)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=train_df, x='Age', y='RoomService', hue=train_df['Transported'], alpha=0.6)\n",
        "plt.title('Age vs RoomService (Transported)')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Room Service Spend')\n",
        "plt.legend(title='Transported')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_nPps4McVAXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FoodCourt vs Spa (colored by Transported)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=train_df, x='FoodCourt', y='Spa', hue=train_df['Transported'], alpha=0.6)\n",
        "plt.title('FoodCourt vs Spa (Transported)')\n",
        "plt.xlabel('FoodCourt Spend')\n",
        "plt.ylabel('Spa Spend')\n",
        "plt.legend(title='Transported')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n5R_85O3VDk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VRDeck vs ShoppingMall\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=train_df, x='VRDeck', y='ShoppingMall', hue=train_df['Transported'], alpha=0.6)\n",
        "plt.title('VRDeck vs ShoppingMall (Transported)')\n",
        "plt.xlabel('VRDeck Spend')\n",
        "plt.ylabel('ShoppingMall Spend')\n",
        "plt.legend(title='Transported')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jpi7md4gVBAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Combine features and target for plotting\n",
        "\n",
        "eda_df = train_df.copy()\n",
        "eda_df['Transported'] = train_df['Transported'].astype(int)\n",
        "\n",
        "\n",
        "# Limit numeric features to avoid overcrowding\n",
        "plot_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "\n",
        "# Plot pairplot (use sample to speed it up)\n",
        "sns.pairplot(eda_df.sample(500), vars=plot_features, hue='Transported', palette='Set2', corner=True)\n",
        "plt.suptitle(\"Pairplot of Selected Features\", y=1.02)\n",
        "plt.savefig(\"pairplot_features.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xpdEugB5WWrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cols = ['PassengerId', 'Name', 'Cabin']\n",
        "train_df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
        "test_df.drop(columns=drop_cols, inplace=True, errors='ignore')\n"
      ],
      "metadata": {
        "id": "7RYtffs3VO68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Separate label\n",
        "y = train_df['Transported'].astype(int)\n",
        "train_df.drop(columns=['Transported'], inplace=True)"
      ],
      "metadata": {
        "id": "Aa3ggo6gVPnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Identify column types\n",
        "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n"
      ],
      "metadata": {
        "id": "O0G4JPjkVUzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fill missing values\n",
        "train_df[numeric_cols] = train_df[numeric_cols].fillna(train_df[numeric_cols].median())\n",
        "train_df[categorical_cols] = train_df[categorical_cols].apply(lambda col: col.fillna(col.mode()[0]))\n",
        "test_df[numeric_cols] = test_df[numeric_cols].fillna(train_df[numeric_cols].median())\n",
        "test_df[categorical_cols] = test_df[categorical_cols].apply(lambda col: col.fillna(col.mode()[0]))\n",
        "\n",
        "\n",
        "# One-hot encode\n",
        "train_df = pd.get_dummies(train_df, columns=categorical_cols)\n",
        "test_df = pd.get_dummies(test_df, columns=categorical_cols)\n",
        "\n",
        "# Align columns\n",
        "train_df, test_df = train_df.align(test_df, join='left', axis=1, fill_value=0)\n"
      ],
      "metadata": {
        "id": "SQZYB3kEVZRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(train_df)\n",
        "X_scaled = np.nan_to_num(X_scaled)\n",
        "X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
        "\n",
        "X_test = scaler.transform(test_df)\n",
        "X_test = np.nan_to_num(X_test)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n"
      ],
      "metadata": {
        "id": "ck_TE500Vctw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "#train_df.drop(columns=['TotalSpend'], inplace=True)"
      ],
      "metadata": {
        "id": "I1aKqja9VnFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Ensure data is scaled\n",
        "X_pca = PCA(n_components=2).fit_transform(X_scaled.reshape(X_scaled.shape[0], -1))\n",
        "\n",
        "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
        "pca_df['Transported'] = y.values\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='Transported', palette='Set1', alpha=0.6)\n",
        "plt.title('PCA Projection of Features')\n",
        "plt.savefig(\"pca_projection.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z4vrBepeWXn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, GlobalAveragePooling1D, Dense, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(64, kernel_size=3, padding='same', input_shape=(X_train.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv1D(128, kernel_size=3, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv1D(64, kernel_size=3, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    GlobalAveragePooling1D(),\n",
        "\n",
        "    Dense(64),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),  # slightly reduced LR for stability\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "AEx9PirzZioj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv1D(32, kernel_size=3, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "D5m8WqUKVqtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[early_stop],\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "pObSo8zHV37u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label=\"Train Acc\")\n",
        "plt.plot(history.history['val_accuracy'], label=\"Val Acc\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label=\"Train Loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Val Loss\")\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q_1C86HRV-jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_preds = (model.predict(X_val) > 0.5).astype(int)\n",
        "\n",
        "print(\"\\nüîç Classification Report:\")\n",
        "print(classification_report(y_val, val_preds))\n",
        "\n",
        "print(\"\\nüßæ Confusion Matrix:\")\n",
        "sns.heatmap(confusion_matrix(y_val, val_preds), annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "42QydkurWG7l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}